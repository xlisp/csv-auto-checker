ä¸‹é¢æ˜¯ä½¿ç”¨ PySpark çš„ `exceptAll()` æ–¹æ³•é‡å†™çš„ç‰ˆæœ¬ï¼š

```python
#!/usr/bin/env python3
"""
CSV è‡ªåŠ¨å¯¹æ¯”å·¥å…· - PySparkç‰ˆæœ¬
ä½¿ç”¨ Spark DataFrame çš„ exceptAll æ–¹æ³•è¿›è¡Œé«˜æ€§èƒ½å¯¹æ¯”
"""

from pyspark.sql import SparkSession
from pyspark.sql import DataFrame
from pyspark.sql.functions import col, lit, concat_ws, md5, monotonically_increasing_id
from typing import List, Dict, Any, Tuple
from datetime import datetime
import logging
import argparse

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class SparkCSVComparator:
    """åŸºäºPySparkçš„CSVå¯¹æ¯”å·¥å…·"""

    def __init__(self, exclude_fields: List[str] = None, sample_rate: float = 1.0):
        """
        åˆå§‹åŒ–å¯¹æ¯”å™¨

        Args:
            exclude_fields: æ’é™¤ä¸æ¯”è¾ƒçš„å­—æ®µåˆ—è¡¨
            sample_rate: æŠ½æ ·ç‡ï¼ˆ0-1ä¹‹é—´ï¼‰
        """
        self.exclude_fields = exclude_fields or []
        self.sample_rate = sample_rate
        self.comparison_results = {}
        
        # åˆå§‹åŒ–Spark Session
        self.spark = SparkSession.builder \
            .appName("CSV_Comparator") \
            .config("spark.sql.adaptive.enabled", "true") \
            .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
            .getOrCreate()
        
        logger.info("Spark Session å·²åˆ›å»º")

    def load_csv(self, file_path: str, header: bool = True, 
                 infer_schema: bool = True) -> DataFrame:
        """
        åŠ è½½CSVæ–‡ä»¶ä¸ºSpark DataFrame

        Args:
            file_path: CSVæ–‡ä»¶è·¯å¾„
            header: æ˜¯å¦åŒ…å«è¡¨å¤´
            infer_schema: æ˜¯å¦è‡ªåŠ¨æ¨æ–­schema

        Returns:
            Spark DataFrame
        """
        logger.info(f"å¼€å§‹åŠ è½½CSVæ–‡ä»¶: {file_path}")
        
        try:
            df = self.spark.read.csv(
                file_path,
                header=header,
                inferSchema=infer_schema,
                encoding='utf-8'
            )
            
            count = df.count()
            logger.info(f"æˆåŠŸåŠ è½½ {count} è¡Œæ•°æ®ï¼Œ{len(df.columns)} åˆ—")
            logger.info(f"åˆ—å: {df.columns}")
            
            return df
            
        except Exception as e:
            logger.error(f"åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {e}")
            raise

    def prepare_dataframe(self, df: DataFrame) -> DataFrame:
        """
        å‡†å¤‡DataFrameç”¨äºå¯¹æ¯”ï¼ˆç§»é™¤æ’é™¤å­—æ®µï¼‰

        Args:
            df: åŸå§‹DataFrame

        Returns:
            å¤„ç†åçš„DataFrame
        """
        if self.exclude_fields:
            logger.info(f"æ’é™¤å­—æ®µ: {', '.join(self.exclude_fields)}")
            compare_cols = [c for c in df.columns if c not in self.exclude_fields]
            df = df.select(compare_cols)
        
        # å¦‚æœéœ€è¦æŠ½æ ·
        if self.sample_rate < 1.0:
            logger.info(f"æ‰§è¡ŒæŠ½æ ·ï¼ŒæŠ½æ ·ç‡: {self.sample_rate}")
            df = df.sample(fraction=self.sample_rate, seed=42)
        
        return df

    def compare_dataframes(self, df1: DataFrame, df2: DataFrame) -> Dict[str, Any]:
        """
        ä½¿ç”¨ exceptAll å¯¹æ¯”ä¸¤ä¸ªDataFrame

        Args:
            df1: ç¬¬ä¸€ä¸ªDataFrame
            df2: ç¬¬äºŒä¸ªDataFrame

        Returns:
            å¯¹æ¯”ç»“æœå­—å…¸
        """
        logger.info("å¼€å§‹å¯¹æ¯”DataFrame...")
        
        # ç¡®ä¿ä¸¤ä¸ªDataFrameçš„åˆ—é¡ºåºä¸€è‡´
        if set(df1.columns) != set(df2.columns):
            raise ValueError("ä¸¤ä¸ªCSVæ–‡ä»¶çš„åˆ—ä¸ä¸€è‡´ï¼")
        
        # ç»Ÿä¸€åˆ—é¡ºåº
        columns = sorted(df1.columns)
        df1 = df1.select(columns)
        df2 = df2.select(columns)
        
        # ç»Ÿè®¡æ€»è¡Œæ•°
        total_df1 = df1.count()
        total_df2 = df2.count()
        
        logger.info(f"DataFrame1 è¡Œæ•°: {total_df1}")
        logger.info(f"DataFrame2 è¡Œæ•°: {total_df2}")
        
        # ä½¿ç”¨ exceptAll æ‰¾å‡ºå·®å¼‚
        # df1.exceptAll(df2): åœ¨df1ä¸­ä½†ä¸åœ¨df2ä¸­çš„è¡Œï¼ˆä¿ç•™é‡å¤ï¼‰
        only_in_df1 = df1.exceptAll(df2)
        
        # df2.exceptAll(df1): åœ¨df2ä¸­ä½†ä¸åœ¨df1ä¸­çš„è¡Œï¼ˆä¿ç•™é‡å¤ï¼‰
        only_in_df2 = df2.exceptAll(df1)
        
        # ç¼“å­˜ç»“æœä»¥æé«˜æ€§èƒ½
        only_in_df1.cache()
        only_in_df2.cache()
        
        count_only_df1 = only_in_df1.count()
        count_only_df2 = only_in_df2.count()
        
        logger.info(f"ä»…åœ¨æ–‡ä»¶1ä¸­: {count_only_df1} è¡Œ")
        logger.info(f"ä»…åœ¨æ–‡ä»¶2ä¸­: {count_only_df2} è¡Œ")
        
        # è®¡ç®—ç›¸åŒçš„è¡Œæ•°
        identical_rows = total_df1 - count_only_df1
        
        results = {
            'total_rows_df1': total_df1,
            'total_rows_df2': total_df2,
            'identical_rows': identical_rows,
            'only_in_df1': count_only_df1,
            'only_in_df2': count_only_df2,
            'df1_only_data': only_in_df1,
            'df2_only_data': only_in_df2,
            'columns': columns
        }
        
        return results

    def compare_csvs(self, file1: str, file2: str,
                    output_html: str = "comparison_report.html",
                    export_csv_prefix: str = None) -> Dict[str, Any]:
        """
        å¯¹æ¯”ä¸¤ä¸ªCSVæ–‡ä»¶

        Args:
            file1, file2: CSVæ–‡ä»¶è·¯å¾„
            output_html: è¾“å‡ºHTMLæŠ¥å‘Šè·¯å¾„
            export_csv_prefix: å¯¼å‡ºCSVçš„è·¯å¾„å‰ç¼€

        Returns:
            å¯¹æ¯”ç»“æœ
        """
        logger.info("=" * 60)
        logger.info("å¼€å§‹CSVå¯¹æ¯”æµç¨‹")
        logger.info("=" * 60)
        
        # åŠ è½½æ•°æ®
        df1 = self.load_csv(file1)
        df2 = self.load_csv(file2)
        
        # å‡†å¤‡æ•°æ®ï¼ˆç§»é™¤æ’é™¤å­—æ®µã€æŠ½æ ·ï¼‰
        df1_prepared = self.prepare_dataframe(df1)
        df2_prepared = self.prepare_dataframe(df2)
        
        # æ‰§è¡Œå¯¹æ¯”
        results = self.compare_dataframes(df1_prepared, df2_prepared)
        
        # å¯¼å‡ºå·®å¼‚æ•°æ®åˆ°CSV
        if export_csv_prefix:
            self.export_differences_csv(results, export_csv_prefix)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        self.generate_html_report(results, file1, file2, output_html)
        
        # å­˜å‚¨ç»“æœ
        self.comparison_results = results
        
        return results

    def export_differences_csv(self, results: Dict[str, Any], output_prefix: str):
        """
        å¯¼å‡ºå·®å¼‚æ•°æ®ä¸ºCSV

        Args:
            results: å¯¹æ¯”ç»“æœ
            output_prefix: è¾“å‡ºè·¯å¾„å‰ç¼€
        """
        logger.info("å¼€å§‹å¯¼å‡ºå·®å¼‚æ•°æ®...")
        
        # å¯¼å‡ºä»…åœ¨æ–‡ä»¶1ä¸­çš„æ•°æ®
        if results['only_in_df1'] > 0:
            output1 = f"{output_prefix}_only_in_file1.csv"
            results['df1_only_data'].coalesce(1).write.csv(
                output1,
                header=True,
                mode='overwrite'
            )
            logger.info(f"ä»…åœ¨æ–‡ä»¶1ä¸­çš„æ•°æ®å·²å¯¼å‡º: {output1}")
        
        # å¯¼å‡ºä»…åœ¨æ–‡ä»¶2ä¸­çš„æ•°æ®
        if results['only_in_df2'] > 0:
            output2 = f"{output_prefix}_only_in_file2.csv"
            results['df2_only_data'].coalesce(1).write.csv(
                output2,
                header=True,
                mode='overwrite'
            )
            logger.info(f"ä»…åœ¨æ–‡ä»¶2ä¸­çš„æ•°æ®å·²å¯¼å‡º: {output2}")

    def generate_html_report(self, results: Dict[str, Any],
                           file1: str, file2: str, output_path: str):
        """
        ç”ŸæˆHTMLå¯¹æ¯”æŠ¥å‘Š

        Args:
            results: å¯¹æ¯”ç»“æœ
            file1, file2: æºæ–‡ä»¶è·¯å¾„
            output_path: HTMLè¾“å‡ºè·¯å¾„
        """
        logger.info("å¼€å§‹ç”ŸæˆHTMLæŠ¥å‘Š...")
        
        # æ”¶é›†æ ·æœ¬æ•°æ®ç”¨äºå±•ç¤º
        df1_sample = []
        df2_sample = []
        
        if results['only_in_df1'] > 0:
            df1_sample = results['df1_only_data'].limit(50).collect()
        
        if results['only_in_df2'] > 0:
            df2_sample = results['df2_only_data'].limit(50).collect()
        
        columns = results['columns']
        
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>CSVå¯¹æ¯”æŠ¥å‘Š - PySparkç‰ˆæœ¬</title>
    <meta charset="UTF-8">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1400px; margin: 0 auto; background-color: white; padding: 30px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 10px; margin-bottom: 30px; }}
        .header h1 {{ margin: 0 0 15px 0; }}
        .header p {{ margin: 5px 0; opacity: 0.9; }}
        .summary {{ margin: 30px 0; }}
        .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }}
        .stat-box {{ 
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 25px;
            border-radius: 10px;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }}
        .stat-box h3 {{ margin: 0; font-size: 2.5em; font-weight: bold; }}
        .stat-box p {{ margin: 10px 0 0 0; font-size: 1.1em; opacity: 0.9; }}
        .differences {{ margin: 30px 0; }}
        .section-title {{ 
            color: #667eea;
            font-size: 1.5em;
            margin: 30px 0 15px 0;
            padding-bottom: 10px;
            border-bottom: 3px solid #667eea;
        }}
        .diff-table {{ 
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .diff-table th {{ 
            background-color: #667eea;
            color: white;
            padding: 12px;
            text-align: left;
            font-weight: bold;
        }}
        .diff-table td {{ 
            border: 1px solid #ddd;
            padding: 10px;
            text-align: left;
        }}
        .diff-table tr:nth-child(even) {{ background-color: #f9f9f9; }}
        .diff-table tr:hover {{ background-color: #f0f0f0; }}
        .excluded-fields {{ 
            background-color: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }}
        .no-data {{ 
            color: #666;
            font-style: italic;
            text-align: center;
            padding: 30px;
            background-color: #f9f9f9;
            border-radius: 5px;
        }}
        .badge {{ 
            display: inline-block;
            padding: 5px 10px;
            background-color: #667eea;
            color: white;
            border-radius: 5px;
            font-size: 0.9em;
            margin-left: 10px;
        }}
        .info-box {{
            background-color: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ” CSVæ–‡ä»¶å¯¹æ¯”æŠ¥å‘Š</h1>
            <p><strong>æ–‡ä»¶1:</strong> {file1}</p>
            <p><strong>æ–‡ä»¶2:</strong> {file2}</p>
            <p><strong>å¯¹æ¯”æ—¶é—´:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p><strong>å¯¹æ¯”å¼•æ“:</strong> Apache Spark (exceptAllæ–¹æ³•) <span class="badge">é«˜æ€§èƒ½</span></p>
        </div>
"""

        if self.exclude_fields:
            html_content += f"""
        <div class="excluded-fields">
            <strong>âš ï¸ æ’é™¤æ¯”è¾ƒçš„å­—æ®µ:</strong> {', '.join(self.exclude_fields)}
        </div>
"""

        if self.sample_rate < 1.0:
            html_content += f"""
        <div class="info-box">
            <strong>ğŸ“Š æŠ½æ ·ä¿¡æ¯:</strong> ä½¿ç”¨ {self.sample_rate * 100}% æŠ½æ ·ç‡è¿›è¡Œå¯¹æ¯”
        </div>
"""

        html_content += f"""
        <div class="summary">
            <h2 class="section-title">ğŸ“ˆ å¯¹æ¯”æ‘˜è¦</h2>
            <div class="stats">
                <div class="stat-box">
                    <h3>{results['total_rows_df1']:,}</h3>
                    <p>æ–‡ä»¶1æ€»è¡Œæ•°</p>
                </div>
                <div class="stat-box">
                    <h3>{results['total_rows_df2']:,}</h3>
                    <p>æ–‡ä»¶2æ€»è¡Œæ•°</p>
                </div>
                <div class="stat-box">
                    <h3>{results['identical_rows']:,}</h3>
                    <p>å®Œå…¨ç›¸åŒè¡Œæ•°</p>
                </div>
                <div class="stat-box">
                    <h3>{results['only_in_df1']:,}</h3>
                    <p>ä»…åœ¨æ–‡ä»¶1ä¸­</p>
                </div>
                <div class="stat-box">
                    <h3>{results['only_in_df2']:,}</h3>
                    <p>ä»…åœ¨æ–‡ä»¶2ä¸­</p>
                </div>
            </div>
        </div>

        <div class="differences">
            <h2 class="section-title">ğŸ“‹ ä»…åœ¨æ–‡ä»¶1ä¸­çš„è¡Œ (å‰50æ¡)</h2>
"""

        if not df1_sample:
            html_content += '<p class="no-data">âœ“ æ— ç‹¬æœ‰æ•°æ®</p>'
        else:
            html_content += '<div style="overflow-x: auto;"><table class="diff-table">'
            html_content += '<tr>' + ''.join(f'<th>{col}</th>' for col in columns) + '</tr>'
            
            for row in df1_sample:
                html_content += '<tr>' + ''.join(f'<td>{row[col]}</td>' for col in columns) + '</tr>'
            
            html_content += '</table></div>'

        html_content += """
            <h2 class="section-title">ğŸ“‹ ä»…åœ¨æ–‡ä»¶2ä¸­çš„è¡Œ (å‰50æ¡)</h2>
"""

        if not df2_sample:
            html_content += '<p class="no-data">âœ“ æ— ç‹¬æœ‰æ•°æ®</p>'
        else:
            html_content += '<div style="overflow-x: auto;"><table class="diff-table">'
            html_content += '<tr>' + ''.join(f'<th>{col}</th>' for col in columns) + '</tr>'
            
            for row in df2_sample:
                html_content += '<tr>' + ''.join(f'<td>{row[col]}</td>' for col in columns) + '</tr>'
            
            html_content += '</table></div>'

        html_content += """
        </div>

        <div class="summary">
            <h2 class="section-title">â„¹ï¸ å¯¹æ¯”è¯´æ˜</h2>
            <div class="info-box">
                <ul style="margin: 10px 0; padding-left: 20px;">
                    <li><strong>å¯¹æ¯”æ–¹æ³•:</strong> ä½¿ç”¨ Apache Spark çš„ <code>exceptAll()</code> æ–¹æ³•è¿›è¡Œåˆ†å¸ƒå¼å¯¹æ¯”</li>
                    <li><strong>ç›¸åŒè¡Œ:</strong> ä¸¤ä¸ªæ–‡ä»¶ä¸­å†…å®¹å®Œå…¨ä¸€è‡´çš„è¡Œï¼ˆåŒ…æ‹¬é‡å¤è¡Œï¼‰</li>
                    <li><strong>ä»…åœ¨æ–‡ä»¶1ä¸­:</strong> åœ¨æ–‡ä»¶1ä¸­å­˜åœ¨ä½†æ–‡ä»¶2ä¸­ä¸å­˜åœ¨çš„è¡Œ</li>
                    <li><strong>ä»…åœ¨æ–‡ä»¶2ä¸­:</strong> åœ¨æ–‡ä»¶2ä¸­å­˜åœ¨ä½†æ–‡ä»¶1ä¸­ä¸å­˜åœ¨çš„è¡Œ</li>
                    <li><strong>æ€§èƒ½ä¼˜åŠ¿:</strong> ä½¿ç”¨Sparkåˆ†å¸ƒå¼è®¡ç®—ï¼Œæ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†å¯¹æ¯”</li>
                </ul>
            </div>
        </div>
    </div>
</body>
</html>
"""

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        logger.info(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")

    def stop(self):
        """åœæ­¢Spark Session"""
        if self.spark:
            self.spark.stop()
            logger.info("Spark Session å·²åœæ­¢")


def main():
    """å‘½ä»¤è¡Œä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='CSVè‡ªåŠ¨å¯¹æ¯”å·¥å…· - PySparkç‰ˆæœ¬ (ä½¿ç”¨exceptAllæ–¹æ³•)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬å¯¹æ¯”
  python spark_csv_comparator.py file1.csv file2.csv
  
  # æ’é™¤æŸäº›å­—æ®µ
  python spark_csv_comparator.py file1.csv file2.csv --exclude timestamp update_time
  
  # 10%æŠ½æ ·å¯¹æ¯”
  python spark_csv_comparator.py file1.csv file2.csv --sample-rate 0.1
  
  # å¯¼å‡ºå·®å¼‚æ•°æ®
  python spark_csv_comparator.py file1.csv file2.csv --export-csv diff_output
        """
    )
    
    parser.add_argument('file1', help='ç¬¬ä¸€ä¸ªCSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('file2', help='ç¬¬äºŒä¸ªCSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--exclude', '-e', nargs='+', default=[], 
                       dest='exclude_fields',
                       help='æ’é™¤ä¸æ¯”è¾ƒçš„å­—æ®µåˆ—è¡¨')
    parser.add_argument('--sample-rate', '-s', type=float, default=1.0,
                       help='æŠ½æ ·ç‡ (0-1)ï¼Œé»˜è®¤1.0å…¨é‡å¯¹æ¯”')
    parser.add_argument('--output', '-o', default='comparison_report.html',
                       help='è¾“å‡ºHTMLæŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--export-csv', help='å¯¼å‡ºå·®å¼‚æ•°æ®CSVè·¯å¾„å‰ç¼€')

    args = parser.parse_args()

    # éªŒè¯æŠ½æ ·ç‡
    if not 0 < args.sample_rate <= 1.0:
        parser.error("æŠ½æ ·ç‡å¿…é¡»åœ¨ 0 å’Œ 1 ä¹‹é—´")

    # åˆ›å»ºå¯¹æ¯”å™¨
    comparator = SparkCSVComparator(
        exclude_fields=args.exclude_fields,
        sample_rate=args.sample_rate
    )

    try:
        # æ‰§è¡Œå¯¹æ¯”
        results = comparator.compare_csvs(
            args.file1,
            args.file2,
            args.output,
            args.export_csv
        )

        # æ‰“å°æ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š å¯¹æ¯”å®Œæˆ")
        print("=" * 60)
        print(f"æ–‡ä»¶1æ€»è¡Œæ•°:    {results['total_rows_df1']:,}")
        print(f"æ–‡ä»¶2æ€»è¡Œæ•°:    {results['total_rows_df2']:,}")
        print(f"ç›¸åŒè¡Œæ•°:      {results['identical_rows']:,}")
        print(f"ä»…åœ¨æ–‡ä»¶1ä¸­:   {results['only_in_df1']:,} è¡Œ")
        print(f"ä»…åœ¨æ–‡ä»¶2ä¸­:   {results['only_in_df2']:,} è¡Œ")
        print(f"HTMLæŠ¥å‘Š:      {args.output}")
        
        if args.export_csv:
            print(f"å·®å¼‚æ•°æ®å·²å¯¼å‡ºåˆ°: {args.export_csv}_only_in_file*.csv")
        
        print("=" * 60)

        return 0

    except Exception as e:
        logger.error(f"å¯¹æ¯”è¿‡ç¨‹å‡ºé”™: {e}", exc_info=True)
        return 1

    finally:
        # åœæ­¢Spark Session
        comparator.stop()


if __name__ == "__main__":
    exit(main())
```

**ä¸»è¦ç‰¹ç‚¹ï¼š**

1. **ä½¿ç”¨ PySpark çš„ `exceptAll()` æ–¹æ³•**ï¼š
   - `df1.exceptAll(df2)` - æ‰¾å‡ºåœ¨ df1 ä¸­ä½†ä¸åœ¨ df2 ä¸­çš„è¡Œ
   - `df2.exceptAll(df1)` - æ‰¾å‡ºåœ¨ df2 ä¸­ä½†ä¸åœ¨ df1 ä¸­çš„è¡Œ
   - ä¿ç•™é‡å¤è¡Œï¼Œå®Œå…¨ç­‰åŒäº Spark çš„è¡Œä¸º

2. **åˆ†å¸ƒå¼è®¡ç®—**ï¼š
   - æ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†
   - è‡ªåŠ¨å¹¶è¡Œå¤„ç†
   - é…ç½®äº†è‡ªé€‚åº”æŸ¥è¯¢æ‰§è¡Œ

3. **æ— éœ€ä¸»é”®**ï¼š
   - æ•´è¡Œå†…å®¹å¯¹æ¯”
   - ä¸éœ€è¦æŒ‡å®šä»»ä½•ä¸»é”®åˆ—

4. **åŠŸèƒ½å®Œæ•´**ï¼š
   - æ”¯æŒæ’é™¤å­—æ®µ
   - æ”¯æŒæŠ½æ ·å¯¹æ¯”
   - ç”ŸæˆHTMLæŠ¥å‘Š
   - å¯¼å‡ºå·®å¼‚æ•°æ®åˆ°CSV

**ä½¿ç”¨æ–¹æ³•ï¼š**

```bash
# å®‰è£…PySpark
pip install pyspark

# åŸºæœ¬å¯¹æ¯”
python spark_csv_comparator.py file1.csv file2.csv

# æ’é™¤æŸäº›å­—æ®µ
python spark_csv_comparator.py file1.csv file2.csv --exclude id timestamp

# 10%æŠ½æ ·
python spark_csv_comparator.py file1.csv file2.csv --sample-rate 0.1

# å¯¼å‡ºå·®å¼‚
python spark_csv_comparator.py file1.csv file2.csv --export-csv diff_result
```

è¿™ä¸ªç‰ˆæœ¬ä½¿ç”¨äº†çœŸæ­£çš„ Spark `exceptAll()` æ–¹æ³•ï¼Œæ€§èƒ½æ›´å¥½ï¼Œç‰¹åˆ«é€‚åˆå¤§æ•°æ®åœºæ™¯ï¼

